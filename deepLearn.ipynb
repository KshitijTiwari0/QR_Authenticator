{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_images(folder_path, label):\n",
    "    \"\"\"\n",
    "    Loads grayscale images from a folder and returns them along with the label.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            # Resize to a fixed size (optional, here we use 128x128)\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "def compute_features(image):\n",
    "    \"\"\"\n",
    "    Extract several features from a given QR image:\n",
    "      - Laplacian variance: Edge sharpness.\n",
    "      - Mean intensity: Overall brightness.\n",
    "      - Standard deviation: Contrast measure.\n",
    "      - Dark pixel ratio: Proportion of dark pixels after thresholding.\n",
    "    \"\"\"\n",
    "    # Laplacian variance for edge sharpness\n",
    "    lap_var = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "    # Mean and standard deviation of pixel intensities\n",
    "    mean_intensity = np.mean(image)\n",
    "    std_intensity = np.std(image)\n",
    "\n",
    "    # Threshold image to binary (assumes QR codes are mostly black & white)\n",
    "    _, thresh = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)\n",
    "    # Dark pixels (value 0) ratio\n",
    "    dark_ratio = np.sum(thresh == 0) / thresh.size\n",
    "\n",
    "    return lap_var, mean_intensity, std_intensity, dark_ratio\n",
    "\n",
    "def analyze_dataset(original_folder, counterfeit_folder):\n",
    "    # Load images from each folder\n",
    "    orig_imgs, orig_labels = load_images(original_folder, 0)\n",
    "    counterfeit_imgs, counterfeit_labels = load_images(counterfeit_folder, 1)\n",
    "\n",
    "    # Combine datasets for later use if needed\n",
    "    all_imgs = orig_imgs + counterfeit_imgs\n",
    "    all_labels = orig_labels + counterfeit_labels\n",
    "\n",
    "    # Extract features\n",
    "    features = {\"lap_var\": [], \"mean\": [], \"std\": [], \"dark_ratio\": []}\n",
    "    labels = []  # 0 for original, 1 for counterfeit\n",
    "    for img, lab in zip(all_imgs, all_labels):\n",
    "        f = compute_features(img)\n",
    "        features[\"lap_var\"].append(f[0])\n",
    "        features[\"mean\"].append(f[1])\n",
    "        features[\"std\"].append(f[2])\n",
    "        features[\"dark_ratio\"].append(f[3])\n",
    "        labels.append(lab)\n",
    "\n",
    "    features = {k: np.array(v) for k, v in features.items()}\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features, labels, orig_imgs, counterfeit_imgs\n",
    "\n",
    "def plot_feature_distributions(features, labels, feature_name, class_names=[\"Original\", \"Counterfeit\"]):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(features[feature_name][labels==0], color='blue', label=class_names[0], kde=True, stat=\"density\", bins=20)\n",
    "    sns.histplot(features[feature_name][labels==1], color='red', label=class_names[1], kde=True, stat=\"density\", bins=20)\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.title(f\"Distribution of {feature_name}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# # Set your folder paths here\n",
    "original_folder = \"/content/drive/MyDrive/Datasets/QR_Classifier/First Print\"      # e.g., \"./data/original\"\n",
    "counterfeit_folder = \"/content/drive/MyDrive/Datasets/QR_Classifier/Second Print\"  # e.g., \"./data/counterfeit\"\n",
    "\n",
    "\n",
    "# Analyze dataset and extract features\n",
    "features, labels, orig_imgs, counterfeit_imgs = analyze_dataset(original_folder, counterfeit_folder)\n",
    "\n",
    "# Print basic statistics\n",
    "print(\"Feature Statistics:\")\n",
    "for key, vals in features.items():\n",
    "    print(f\"{key} (Original): mean={np.mean(vals[labels==0]):.2f}, std={np.std(vals[labels==0]):.2f}\")\n",
    "    print(f\"{key} (Counterfeit): mean={np.mean(vals[labels==1]):.2f}, std={np.std(vals[labels==1]):.2f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "# Plot feature distributions for comparison\n",
    "plot_feature_distributions(features, labels, \"lap_var\")\n",
    "plot_feature_distributions(features, labels, \"mean\")\n",
    "plot_feature_distributions(features, labels, \"std\")\n",
    "plot_feature_distributions(features, labels, \"dark_ratio\")\n",
    "\n",
    "# Optionally, visualize a few sample images from each class\n",
    "def show_samples(images, title, num=5):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i in range(num):\n",
    "        plt.subplot(1, num, i+1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_samples(orig_imgs, \"Original\")\n",
    "show_samples(counterfeit_imgs, \"Counterfeit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub  # If needed for EfficientNet from TF Hub\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, BatchNormalization,\n",
    "                                     GlobalAveragePooling2D, concatenate)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# -------------------------------\n",
    "# 1. GLCM Feature Extraction\n",
    "# -------------------------------\n",
    "def extract_glcm_features(gray_img, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    \"\"\"\n",
    "    Compute GLCM features (contrast, dissimilarity, homogeneity, energy, correlation, ASM)\n",
    "    averaged over multiple distances & angles.\n",
    "\n",
    "    :param gray_img: Grayscale image (2D NumPy array)\n",
    "    :param distances: list of pixel distances\n",
    "    :param angles: list of angles in radians\n",
    "    :return: 1D NumPy array of GLCM feature means\n",
    "    \"\"\"\n",
    "    # Ensure 8-bit grayscale\n",
    "    gray_img = gray_img.astype(np.uint8)\n",
    "\n",
    "    # Compute GLCM\n",
    "    glcm = greycomatrix(gray_img, distances=distances, angles=angles,\n",
    "                        levels=256, symmetric=True, normed=True)\n",
    "\n",
    "    features = []\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "    for prop in props:\n",
    "        vals = greycoprops(glcm, prop)\n",
    "        mean_val = np.mean(vals)\n",
    "        features.append(mean_val)\n",
    "\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Data Loading\n",
    "# -------------------------------\n",
    "def load_images_and_labels(original_dir, counterfeit_dir):\n",
    "    \"\"\"\n",
    "    Loads images from two folders (original, counterfeit).\n",
    "    Returns a list of images and corresponding labels (0=original, 1=counterfeit).\n",
    "    \"\"\"\n",
    "    original_paths = [os.path.join(original_dir, f)\n",
    "                      for f in os.listdir(original_dir) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
    "    counterfeit_paths = [os.path.join(counterfeit_dir, f)\n",
    "                         for f in os.listdir(counterfeit_dir) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
    "\n",
    "    X_imgs = []\n",
    "    y_labels = []\n",
    "\n",
    "    # Label 0 for original\n",
    "    for p in original_paths:\n",
    "        img = cv2.imread(p, cv2.IMREAD_COLOR)  # We'll do color for EfficientNet\n",
    "        if img is not None:\n",
    "            X_imgs.append(img)\n",
    "            y_labels.append(0)\n",
    "\n",
    "    # Label 1 for counterfeit\n",
    "    for p in counterfeit_paths:\n",
    "        img = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "        if img is not None:\n",
    "            X_imgs.append(img)\n",
    "            y_labels.append(1)\n",
    "\n",
    "    return X_imgs, np.array(y_labels)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. EfficientNet Feature Extraction (Image Embeddings)\n",
    "# -------------------------------\n",
    "def create_efficientnet_encoder():\n",
    "    \"\"\"\n",
    "    Create a pretrained EfficientNetB0 model for extracting image embeddings\n",
    "    (excluding final classification layers).\n",
    "    \"\"\"\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # We'll get a 1280-d vector for B0\n",
    "    encoder = tf.keras.Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "    # Freeze base layers for faster training (optional)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return encoder\n",
    "\n",
    "def preprocess_efficientnet(img):\n",
    "    \"\"\"\n",
    "    Preprocess image to 224x224 with 3 channels for EfficientNet.\n",
    "    \"\"\"\n",
    "    img_resized = cv2.resize(img, (224,224))\n",
    "    img_resized = img_resized[..., ::-1]  # BGR -> RGB if needed\n",
    "    img_resized = img_resized.astype(np.float32)\n",
    "    return preprocess_input(img_resized)  # From tf.keras.applications.efficientnet\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Hybrid Model (CNN Embeddings + GLCM Features)\n",
    "# -------------------------------\n",
    "def build_hybrid_model(effnet_dim, glcm_dim):\n",
    "    \"\"\"\n",
    "    Build a hybrid model that merges:\n",
    "    - effnet_dim: Dimension of EfficientNet embeddings (e.g. 1280 for B0)\n",
    "    - glcm_dim: Dimension of GLCM features (6 in our example)\n",
    "    \"\"\"\n",
    "    # Image embedding input\n",
    "    img_input = Input(shape=(effnet_dim,), name='img_embedding')\n",
    "\n",
    "    # GLCM feature input\n",
    "    glcm_input = Input(shape=(glcm_dim,), name='glcm_features')\n",
    "\n",
    "    # Merge\n",
    "    merged = concatenate([img_input, glcm_input])\n",
    "\n",
    "    x = Dense(256, activation='relu')(merged)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[img_input, glcm_input], outputs=out)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Putting It All Together\n",
    "# -------------------------------\n",
    "def main_pipeline(original_dir, counterfeit_dir):\n",
    "    # 1. Load images and labels\n",
    "    X_imgs, y = load_images_and_labels(original_dir, counterfeit_dir)\n",
    "\n",
    "    # 2. Prepare arrays for embeddings & GLCM\n",
    "    #    We'll build them for each image\n",
    "    effnet_encoder = create_efficientnet_encoder()  # Pretrained EfficientNet\n",
    "\n",
    "    glcm_features_list = []\n",
    "    effnet_embeddings_list = []\n",
    "\n",
    "    print(\"Extracting features...\")\n",
    "    for img in X_imgs:\n",
    "        # GLCM extraction (on grayscale)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        glcm_feats = extract_glcm_features(gray)  # We'll define this function below\n",
    "        glcm_features_list.append(glcm_feats)\n",
    "\n",
    "        # EfficientNet embedding\n",
    "        prep_img = preprocess_efficientnet(img)  # shape=(224,224,3)\n",
    "        prep_img = np.expand_dims(prep_img, axis=0)  # (1,224,224,3)\n",
    "        emb = effnet_encoder.predict(prep_img)\n",
    "        effnet_embeddings_list.append(emb[0])  # shape=(1280,)\n",
    "\n",
    "    X_glcm = np.array(glcm_features_list)              # shape=(N,6)\n",
    "    X_effnet = np.array(effnet_embeddings_list)        # shape=(N,1280) for B0\n",
    "    print(\"Done. Shapes:\", X_glcm.shape, X_effnet.shape)\n",
    "\n",
    "    # 3. Train/Test Split\n",
    "    X_train_glcm, X_test_glcm, X_train_eff, X_test_eff, y_train, y_test = train_test_split(\n",
    "        X_glcm, X_effnet, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Scale GLCM features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_glcm = scaler.fit_transform(X_train_glcm)\n",
    "    X_test_glcm = scaler.transform(X_test_glcm)\n",
    "\n",
    "    # 4. Build Hybrid Model\n",
    "    hybrid_net = build_hybrid_model(effnet_dim=X_train_eff.shape[1],\n",
    "                                    glcm_dim=X_train_glcm.shape[1])\n",
    "\n",
    "    # 5. Train\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "    ]\n",
    "\n",
    "    history = hybrid_net.fit(\n",
    "        [X_train_eff, X_train_glcm], y_train,\n",
    "        validation_data=([X_test_eff, X_test_glcm], y_test),\n",
    "        epochs=30, batch_size=8, callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # 6. Evaluate\n",
    "    y_pred_prob = hybrid_net.predict([X_test_eff, X_test_glcm])\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # 7. Optional: Evaluate with different thresholds\n",
    "    best_f1 = 0\n",
    "    best_t = 0.5\n",
    "    for t in np.linspace(0.1, 0.9, 50):\n",
    "        yp = (y_pred_prob > t).astype(int)\n",
    "        f1 = f1_score(y_test, yp)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "    print(f\"Best threshold={best_t:.2f} with F1={best_f1:.3f}\")\n",
    "\n",
    "    # 8. Plot training curves\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    return hybrid_net, scaler, best_t\n",
    "\n",
    "# 6. Extra: GLCM extraction function (like we used in the pipeline)\n",
    "def extract_glcm_features(gray_img):\n",
    "    \"\"\"\n",
    "    Example GLCM function that returns 6 features:\n",
    "    contrast, dissimilarity, homogeneity, energy, correlation, ASM\n",
    "    for distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "    then averaged across angles.\n",
    "    \"\"\"\n",
    "\n",
    "    gray_img = gray_img.astype(np.uint8)\n",
    "    distances = [1]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    glcm = graycomatrix(gray_img, distances=distances, angles=angles,\n",
    "                           levels=256, symmetric=True, normed=True)\n",
    "\n",
    "    features = []\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "    for prop in props:\n",
    "        val = graycoprops(glcm, prop)\n",
    "        features.append(val.mean())\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "# 7. Entry Point\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    # Replace with your actual folders containing .png/.jpg\n",
    "    original_dir = \"/content/drive/MyDrive/Datasets/QR_Classifier/First Print\"\n",
    "    counterfeit_dir = \"/content/drive/MyDrive/Datasets/QR_Classifier/Second Print\"\n",
    "\n",
    "\n",
    "\n",
    "    model, glcm_scaler, best_threshold = main_pipeline(original_dir, counterfeit_dir)\n",
    "\n",
    "    # Save model if needed\n",
    "    model.save(\"glcm_efficientnet_hybrid.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
