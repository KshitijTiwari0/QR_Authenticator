{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_images(folder_path, label):\n",
    "    \"\"\"\n",
    "    Loads grayscale images from a folder and returns them along with the label.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            # Resize to a fixed size (optional, here we use 128x128)\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "def compute_features(image):\n",
    "    \"\"\"\n",
    "    Extract several features from a given QR image:\n",
    "      - Laplacian variance: Edge sharpness.\n",
    "      - Mean intensity: Overall brightness.\n",
    "      - Standard deviation: Contrast measure.\n",
    "      - Dark pixel ratio: Proportion of dark pixels after thresholding.\n",
    "    \"\"\"\n",
    "    # Laplacian variance for edge sharpness\n",
    "    lap_var = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "    # Mean and standard deviation of pixel intensities\n",
    "    mean_intensity = np.mean(image)\n",
    "    std_intensity = np.std(image)\n",
    "\n",
    "    # Threshold image to binary (assumes QR codes are mostly black & white)\n",
    "    _, thresh = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)\n",
    "    # Dark pixels (value 0) ratio\n",
    "    dark_ratio = np.sum(thresh == 0) / thresh.size\n",
    "\n",
    "    return lap_var, mean_intensity, std_intensity, dark_ratio\n",
    "\n",
    "def analyze_dataset(original_folder, counterfeit_folder):\n",
    "    # Load images from each folder\n",
    "    orig_imgs, orig_labels = load_images(original_folder, 0)\n",
    "    counterfeit_imgs, counterfeit_labels = load_images(counterfeit_folder, 1)\n",
    "\n",
    "    # Combine datasets for later use if needed\n",
    "    all_imgs = orig_imgs + counterfeit_imgs\n",
    "    all_labels = orig_labels + counterfeit_labels\n",
    "\n",
    "    # Extract features\n",
    "    features = {\"lap_var\": [], \"mean\": [], \"std\": [], \"dark_ratio\": []}\n",
    "    labels = []  # 0 for original, 1 for counterfeit\n",
    "    for img, lab in zip(all_imgs, all_labels):\n",
    "        f = compute_features(img)\n",
    "        features[\"lap_var\"].append(f[0])\n",
    "        features[\"mean\"].append(f[1])\n",
    "        features[\"std\"].append(f[2])\n",
    "        features[\"dark_ratio\"].append(f[3])\n",
    "        labels.append(lab)\n",
    "\n",
    "    features = {k: np.array(v) for k, v in features.items()}\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features, labels, orig_imgs, counterfeit_imgs\n",
    "\n",
    "def plot_feature_distributions(features, labels, feature_name, class_names=[\"Original\", \"Counterfeit\"]):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(features[feature_name][labels==0], color='blue', label=class_names[0], kde=True, stat=\"density\", bins=20)\n",
    "    sns.histplot(features[feature_name][labels==1], color='red', label=class_names[1], kde=True, stat=\"density\", bins=20)\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.title(f\"Distribution of {feature_name}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# # Set your folder paths here\n",
    "original_folder = \"/content/drive/MyDrive/Datasets/QR_Classifier/First Print\"      # e.g., \"./data/original\"\n",
    "counterfeit_folder = \"/content/drive/MyDrive/Datasets/QR_Classifier/Second Print\"  # e.g., \"./data/counterfeit\"\n",
    "\n",
    "\n",
    "# Analyze dataset and extract features\n",
    "features, labels, orig_imgs, counterfeit_imgs = analyze_dataset(original_folder, counterfeit_folder)\n",
    "\n",
    "# Print basic statistics\n",
    "print(\"Feature Statistics:\")\n",
    "for key, vals in features.items():\n",
    "    print(f\"{key} (Original): mean={np.mean(vals[labels==0]):.2f}, std={np.std(vals[labels==0]):.2f}\")\n",
    "    print(f\"{key} (Counterfeit): mean={np.mean(vals[labels==1]):.2f}, std={np.std(vals[labels==1]):.2f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "# Plot feature distributions for comparison\n",
    "plot_feature_distributions(features, labels, \"lap_var\")\n",
    "plot_feature_distributions(features, labels, \"mean\")\n",
    "plot_feature_distributions(features, labels, \"std\")\n",
    "plot_feature_distributions(features, labels, \"dark_ratio\")\n",
    "\n",
    "# Optionally, visualize a few sample images from each class\n",
    "def show_samples(images, title, num=5):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i in range(num):\n",
    "        plt.subplot(1, num, i+1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_samples(orig_imgs, \"Original\")\n",
    "show_samples(counterfeit_imgs, \"Counterfeit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.util import view_as_blocks\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 1. QR Code Property Extraction Functions\n",
    "# ========================================\n",
    "\n",
    "def calculate_print_quality_features(image):\n",
    "    \"\"\"Extract print quality metrics\"\"\"\n",
    "    # Edge sharpness\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    edge_sharpness = laplacian.var()\n",
    "\n",
    "    # Contrast analysis\n",
    "    contrast = np.max(image) - np.min(image)\n",
    "\n",
    "    # Local contrast variance\n",
    "    block_size = (32, 32)\n",
    "    if image.shape[0] < 32 or image.shape[1] < 32:\n",
    "        local_contrast = 0  # Avoid errors on small images\n",
    "    else:\n",
    "        windows = view_as_blocks(image, block_size)\n",
    "        local_contrast = np.var([w.max() - w.min() for w in windows.reshape(-1, 32, 32)])\n",
    "\n",
    "    return [edge_sharpness, contrast, local_contrast]\n",
    "\n",
    "def analyze_structural_patterns(image):\n",
    "    \"\"\"Analyze QR code structural elements\"\"\"\n",
    "    _, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Finder pattern consistency (top-left corner)\n",
    "    finder_region = binary[:21, :21]  # Assuming version 1 QR code\n",
    "    finder_score = np.mean(finder_region == 255)\n",
    "\n",
    "    # Alignment pattern detection\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(c)[:2] for c in contours if 50 < cv2.contourArea(c) < 150]\n",
    "    alignment_deviation = np.std(bounding_boxes) if bounding_boxes else 0\n",
    "\n",
    "    return [finder_score, alignment_deviation]\n",
    "\n",
    "def spectral_analysis(image):\n",
    "    \"\"\"Frequency domain features\"\"\"\n",
    "    fft = np.fft.fft2(image)\n",
    "    fshift = np.fft.fftshift(fft)\n",
    "    magnitude = 20*np.log(np.abs(fshift) + 1e-9)  # Avoid log(0)\n",
    "\n",
    "    # High frequency components\n",
    "    high_freq = magnitude[30:70, 30:70].mean()\n",
    "    # Low frequency components\n",
    "    low_freq = magnitude[100:150, 100:150].mean() if magnitude.shape[0] > 150 else 0\n",
    "\n",
    "    return [high_freq / (low_freq + 1e-9), np.std(magnitude)]\n",
    "\n",
    "def ink_distribution_analysis(image):\n",
    "    \"\"\"Analyze ink distribution patterns\"\"\"\n",
    "    _, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    areas = [cv2.contourArea(c) for c in contours]\n",
    "    eccentricities = []\n",
    "    for c in contours:\n",
    "        if len(c) >= 5:\n",
    "            _, (major, minor), _ = cv2.fitEllipse(c)\n",
    "            if major > 0:\n",
    "                eccentricities.append(np.sqrt(1 - (minor / major) ** 2))\n",
    "\n",
    "    return [np.var(areas) if areas else 0, np.mean(eccentricities) if eccentricities else 0]\n",
    "\n",
    "# 2. Complete Feature Extraction Pipeline\n",
    "# =======================================\n",
    "\n",
    "def extract_qr_features(image):\n",
    "    \"\"\"Combine all quality metrics\"\"\"\n",
    "    image = cv2.resize(image, (128, 128))  # Standardize image size\n",
    "    features = []\n",
    "\n",
    "    # Basic image properties\n",
    "    features += [np.mean(image), np.std(image)]\n",
    "\n",
    "    # Print quality metrics\n",
    "    features += calculate_print_quality_features(image)\n",
    "\n",
    "    # Structural analysis\n",
    "    features += analyze_structural_patterns(image)\n",
    "\n",
    "    # Spectral features\n",
    "    features += spectral_analysis(image)\n",
    "\n",
    "    # Ink distribution\n",
    "    features += ink_distribution_analysis(image)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "# 3. Data Loading and Processing\n",
    "# ==============================\n",
    "\n",
    "def load_images_from_folder(folder, label):\n",
    "    \"\"\"Load images from a folder and assign labels\"\"\"\n",
    "    images, labels = [], []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "def load_dataset(original_path, counterfeit_path):\n",
    "    \"\"\"Load original and counterfeit QR code images\"\"\"\n",
    "    orig_images, orig_labels = load_images_from_folder(original_path, label=0)\n",
    "    fake_images, fake_labels = load_images_from_folder(counterfeit_path, label=1)\n",
    "\n",
    "    X = orig_images + fake_images\n",
    "    y = orig_labels + fake_labels\n",
    "    return X, np.array(y)\n",
    "\n",
    "# 4. Model Training and Evaluation\n",
    "# ================================\n",
    "\n",
    "# Paths to datasets (Change these paths)\n",
    "original_path = \"/content/drive/MyDrive/Datasets/QR_Classifier/First Print\"\n",
    "counterfeit_path = \"/content/drive/MyDrive/Datasets/QR_Classifier/Second Print\"\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_dataset(original_path, counterfeit_path)\n",
    "\n",
    "# Extract features\n",
    "print(\"Extracting features...\")\n",
    "X_features = np.array([extract_qr_features(img) for img in X])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocessing\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=200,\n",
    "                              class_weight='balanced',\n",
    "                              random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 5. Feature Importance Analysis\n",
    "# ==============================\n",
    "feature_names = [\n",
    "    'mean_intensity', 'std_intensity',\n",
    "    'edge_sharpness', 'global_contrast', 'local_contrast_var',\n",
    "    'finder_pattern_score', 'alignment_deviation',\n",
    "    'high_freq_ratio', 'spectral_std',\n",
    "    'ink_area_variance', 'ink_eccentricity'\n",
    "]\n",
    "\n",
    "importances = model.feature_importances_\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, importances)\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.show()\n",
    "\n",
    "# 6. Deployment-ready Prediction\n",
    "# ==============================\n",
    "def authenticate_qrcode(image_path):\n",
    "    \"\"\"Complete authentication pipeline\"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_qr_features(img)\n",
    "    features = scaler.transform([features])\n",
    "\n",
    "    # Predict\n",
    "    proba = model.predict_proba(features)[0][1]\n",
    "    return {\n",
    "        'authentic': proba < 0.5,  # Assuming class 0 is authentic\n",
    "        'confidence': 1 - abs(proba - 0.5) * 2\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
